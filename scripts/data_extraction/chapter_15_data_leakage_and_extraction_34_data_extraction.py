#!/usr/bin/env python3
"""
Differential privacy techniques

Source: Chapter_15_Data_Leakage_and_Extraction
Category: data_extraction
"""

from opacus import PrivacyEngine
import torch.nn as nn
import torch.optim as optim

import argparse
import sys

# Apply differential privacy to model training
model = YourModel()
optimizer = optim.Adam(model.parameters(), lr=0.001)

privacy_engine = PrivacyEngine()

model, optimizer, train_loader = privacy_engine.make_private(
    module=model,
    optimizer=optimizer,
    data_loader=train_loader,
    noise_multiplier=1.1,  # Controls privacy/utility tradeoff
    max_grad_norm=1.0,
)

# Train model with DP guarantees
for epoch in range(num_epochs):
    for data, target in train_loader:
        optimizer.zero_grad()
        output = model(data)
        loss = criterion(output, target)
        loss.backward()
        optimizer.step()

# Get privacy spent
epsilon = privacy_engine.get_epsilon(delta=1e-5)
print(f"Privacy budget (Îµ): {epsilon}")


def main():
    """Command-line interface."""
    parser = argparse.ArgumentParser(description=__doc__)
    parser.add_argument("--verbose", "-v", action="store_true", help="Verbose output")
    args = parser.parse_args()
    
    # TODO: Add main execution logic
    pass

if __name__ == "__main__":
    main()